head(testoftest[,95:98])
head(predC45)
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = FALSE))
head(predC45)
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
head(testoftest[,95:98])
head(predC45))
head(predC45)
sum(predC45[1,])
WOW(J48)
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = TRUE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
WOW(J48)
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
str(train1)
test <- convertincometointeger(convertincome_test(test))
test <- factorise(test)
test$Price1 <- convertpricetointeger(test$Price1)
test$Price2 <- convertpricetointeger(test$Price2)
test$Price3 <- convertpricetointeger(test$Price3)
test$Price4 <- convertpricetointeger(test$Price4)
str(test)
str(train1)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
test <- factorise(test)
test <- factorise(test)
str(test)
test$income <- factor(test$income)
test$Price1 <- convertpricetointeger(test$Price1)
test$Price2 <- convertpricetointeger(test$Price2)
test$Price3 <- convertpricetointeger(test$Price3)
test$Price4 <- convertpricetointeger(test$Price4)
str(test)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
test <- factorise(test)
test$income <- factor(test$income)
test$Price1 <- factor(test$Price1)
test$Price2 <- factor(test$Price2)
test$Price3 <- factor(test$Price3)
test$Price4 <- factor(test$Price4)
str(test)
test <- subset(test, select = - c(1,2,3,95,96,97,98))
train_all <- subset(train1, select = - c(1,2,3,95,96,97,98))
head(train1,1)
str(train1)
str(test)
dim(train1)
dim(test)
dim(train_all)
dim(train)
predC45 <- predict(modelC45, newdata = train_all, type = "probability")
head(predC45, 1)
sum(predC45[1,])
write.csv(predC45, "submissionDay3_2.csv")
modelC45 <- J48(as.factor(Choice) ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test, type = "probability")
predC45 <- predict(modelC45, newdata = test)
head(predC45, 1)
predC45 <- predict(modelC45, newdata = test, type = "probability")
modelC45
summary(modelC45)
predC45 <- predict(modelC45, newdata = test, type = "probability")
head(test,1)
head(test)
dim(test)
dim(train_all)
head(train_all,1)
head(test,1)
grep("income", colnames(train1))
train1 <- train
train1$segment <- factor(train1$segment)
train1$year <- factor(train1$year)
train1$miles <- factor(train1$miles)
train1$night <- factor(train1$night)
train1$gender <- factor(train1$gender)
train1$age <- factor(train1$age)
train1$educ <- factor(train1$educ)
train1$region <- factor(train1$region)
train1$Urb <- factor(train1$Urb)
train1$ppark <- factor(train1$ppark)
train1$Choice <- factor(train1$Choice)
train1$income <- factor(train1$income)
train1$Price1 <- factor(train1$Price1)
train1$Price2 <- factor(train1$Price2)
train1$Price3 <- factor(train1$Price3)
train1$Price4 <- factor(train1$Price4)
spl <- sample.split(train1$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train1, spl == TRUE)
testoftest <- subset(train1, spl == TRUE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,93,95,96,97,98))
testoftestnew <- subset(trainoftrain, select = - c(1,2,3,93,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
test <- factorise(test)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test1 <- test
test1[is.na(test1)] <- 0 # adds 0 to all missing values
test1 <- factorise(test1)
test1$income <- factor(test1$income)
test1$Price1 <- factor(test1$Price1)
test1$Price2 <- factor(test1$Price2)
test1$Price3 <- factor(test1$Price3)
test1$Price4 <- factor(test1$Price4)
train_all <- subset(train1, select = - c(1,2,3,93,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test1, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
write.csv(predC45, "submissionDay3_2.csv")
write.csv(predC45, "submissionDay3_2.csv")
grep("Choice", colnames(train1))
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train1 <- train
train1$segment <- factor(train1$segment)
train1$year <- factor(train1$year)
train1$miles <- factor(train1$miles)
train1$night <- factor(train1$night)
train1$gender <- factor(train1$gender)
train1$age <- factor(train1$age)
train1$educ <- factor(train1$educ)
train1$region <- factor(train1$region)
train1$Urb <- factor(train1$Urb)
train1$ppark <- factor(train1$ppark)
train1$Choice <- factor(train1$Choice)
train1$income <- factor(train1$income)
train1$Price1 <- factor(train1$Price1)
train1$Price2 <- factor(train1$Price2)
train1$Price3 <- factor(train1$Price3)
train1$Price4 <- factor(train1$Price4)
spl <- sample.split(train1$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train1, spl == TRUE)
testoftest <- subset(train1, spl == TRUE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,93,94,95,96,97,98,99))
testoftestnew <- subset(trainoftrain, select = - c(1,2,3,93,94,95,96,97,98,99))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
str(train1)
grep("Price4", colnames(train1))
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train1 <- train
train1$segment <- factor(train1$segment)
train1$year <- factor(train1$year)
train1$miles <- factor(train1$miles)
train1$night <- factor(train1$night)
train1$gender <- factor(train1$gender)
train1$age <- factor(train1$age)
train1$educ <- factor(train1$educ)
train1$region <- factor(train1$region)
train1$Urb <- factor(train1$Urb)
train1$ppark <- factor(train1$ppark)
train1$Choice <- factor(train1$Choice)
train1$income <- factor(train1$income)
train1$Price1 <- factor(train1$Price1)
train1$Price2 <- factor(train1$Price2)
train1$Price3 <- factor(train1$Price3)
train1$Price4 <- factor(train1$Price4)
#train1 <- convertpricetointeger(train1)
#train1 <- convertincometointeger(train1)
spl <- sample.split(train1$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train1, spl == TRUE)
testoftest <- subset(train1, spl == TRUE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,84:98))
testoftestnew <- subset(trainoftrain, select = - c(1,2,3,84:98))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
head(testoftest)
head(testoftest[,95:98])
dim(testoftest[,95:98])
modelC45 <- J48(as.factor(Choice) ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
summary(C45)
summary(modelC45)
modelBag1 <- Bagging(Class ~ ., data = trainoftrainnew, control = Weka_control( W = "weka.classifiers.trees.J48"))
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control( W = "weka.classifiers.trees.J48"))
summary(modelBag1)
rf <- randomForest(Choice ~ ., data = trainoftrainnew, importance = TRUE)
summary(rf)
WOW(CostSensitiveClassifier())
WOW(CostSensitiveClassifier
)
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(cost-matrix = c(0,1,1,1, 1,0,1,1, 1,1,0,1, 1,1,1,0)))
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(cost-matrix = matrix(c(0,1,1,1, 1,0,1,1, 1,1,0,1, 1,1,1,0))))
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(`cost-matrix` = matrix(c(0,1,1,1, 1,0,1,1, 1,1,0,1, 1,1,1,0))))
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(`cost-matrix` = matrix(c(0,1,1,1, 1,0,1,1, 1,1,0,1, 1,1,1,0), nrow = 4, ncol = 4)))
summary(csc1)
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(`cost-matrix` = matrix(c(0,0,0,1, 0,0,0,0, 0,0,0,0, 1,0,0,0), nrow = 4, ncol = 4)))
summary(csc1)
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(`cost-matrix` = matrix(c(0,0,0,0, 0,0,0,0, 0,0,0,0, 0,0,0,0), nrow = 4, ncol = 4)))
summary(csc1)
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all, control = Weka_control(`cost-matrix` = matrix(c(0,0,0,1, 0,0,0,0, 0,0,0,0, 1,0,0,0), nrow = 4, ncol = 4, byrow = TRUE)))
summary(csc1)
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all)#, control = Weka_control(`cost-matrix` = matrix(c(0,0,0,1, 0,0,0,0, 0,0,0,0, 1,0,0,0), nrow = 4, ncol = 4, byrow = TRUE)))
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all)
WOW(Bagging)
modelBag1 <- Bagging(Choice ~ ., data = train_all, control = Weka_control(P = 80, W = "weka.classifiers.trees.J48"))
summary(modelBag1)
modelBag1 <- Bagging(Choice ~ ., data = train_all, control = Weka_control(P = 70, W = "weka.classifiers.trees.J48"))
summary(modelBag1)
modelBag1 <- Bagging(Choice ~ ., data = train_all, control = Weka_control(P = 90, W = "weka.classifiers.trees.J48"))
summary(modelBag1)
modelBag1 <- Bagging(Choice ~ ., data = train_all, control = Weka_control(P = 100, W = "weka.classifiers.trees.J48"))
summary(modelBag1)
predBag <- predict(modelBag1, newdata = train_all, type = "probability")
head(predBag,20)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*train_test2[,16:19]))/N
logloss
train_test2
head(train_test2[,16:19],1)
logloss<- -(sum(log(predBag)*train_test2[,95:98]))/N
logloss
head(train_test2[,85:98],1)
head(train_test2[,95:98],1)
head(train_test2[,95:98],4)
predBag <- predict(modelBag1, newdata = train_test, type = "probability")
modelBag1 <- Bagging(Choice ~ ., data = trainoftrain, control = Weka_control(P = 100, W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftest, type = "probability")
head(predBag,20)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*train_test2[,95:98]))/N
logloss
modelBag1 <- Bagging(Choice ~ ., data = trainoftrain, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftest, type = "probability")
head(predBag,5)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*train_test2[,95:98]))/N
logloss
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftest, type = "probability")
head(predBag,5)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*train_test2[,95:98]))/N
logloss
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftest, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftest, type = "probability")
head(predBag,5)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*testoftest[,95:98]))/N
logloss
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
library(RWeka)
library(FSelector)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train1 <- train
train1$segment <- factor(train1$segment)
train1$year <- factor(train1$year)
train1$miles <- factor(train1$miles)
train1$night <- factor(train1$night)
train1$gender <- factor(train1$gender)
train1$age <- factor(train1$age)
train1$educ <- factor(train1$educ)
train1$region <- factor(train1$region)
train1$Urb <- factor(train1$Urb)
train1$ppark <- factor(train1$ppark)
train1$Choice <- factor(train1$Choice)
train1$income <- factor(train1$income)
train1$Price1 <- factor(train1$Price1)
train1$Price2 <- factor(train1$Price2)
train1$Price3 <- factor(train1$Price3)
train1$Price4 <- factor(train1$Price4)
spl <- sample.split(train1$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train1, spl == TRUE)
testoftest <- subset(train1, spl == TRUE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,95,96,97,98))
testoftestnew <- subset(trainoftrain, select = - c(1,2,3,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss
library(e1071)
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
summary(nb1)
nb1$apriori
prednb1 <- predict(nb1, newdata = testoftestnew, type = "probability")
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
head(prednb1, 1)
N <- nrow(prednb1)
sum(prednb1[1,])
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #0.804071
head(testoftest[,95:98])
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train1 <- train
train1$segment <- factor(train1$segment)
train1$year <- factor(train1$year)
train1$miles <- factor(train1$miles)
train1$night <- factor(train1$night)
train1$gender <- factor(train1$gender)
train1$age <- factor(train1$age)
train1$educ <- factor(train1$educ)
train1$region <- factor(train1$region)
train1$Urb <- factor(train1$Urb)
train1$ppark <- factor(train1$ppark)
train1$Choice <- factor(train1$Choice)
train1$income <- factor(train1$income)
train1$Price1 <- factor(train1$Price1)
train1$Price2 <- factor(train1$Price2)
train1$Price3 <- factor(train1$Price3)
train1$Price4 <- factor(train1$Price4)
spl <- sample.split(train1$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train1, spl == TRUE)
testoftest <- subset(train1, spl == FALSE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,95,96,97,98))
testoftestnew <- subset(trainoftrain, select = - c(1,2,3,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss #0.804071
summary(modelC45)
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftest, type = "probability")
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*testoftest[,95:98]))/N
logloss
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftestnew, type = "probability")
head(predBag,5)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*testoftest[,95:98]))/N
logloss
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
N <- nrow(prednb1)
sum(prednb1[1,])
head(prednb1, 1)
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #1.148192
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test1 <- test
test1[is.na(test1)] <- 0 # adds 0 to all missing values
test1 <- factorise(test1)
test1$income <- factor(test1$income)
test1$Price1 <- factor(test1$Price1)
test1$Price2 <- factor(test1$Price2)
test1$Price3 <- factor(test1$Price3)
test1$Price4 <- factor(test1$Price4)
test1sub <- subset(test1, select = - c(1,2,3,95,96,97,98))
train_all <- subset(train1, select = - c(1,2,3,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test1sub, type = "probability")
dim(train_all)
dim(test1sub)
modelC45 <- J48(Choice ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test1sub, type = "probability")
modelC45 <- J48(Choice ~ ., data = train_all, control = Weka_control())
predC45 <- predict(modelC45, newdata = test1sub, type = "probability")
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test1 <- test
test1[is.na(test1)] <- 0 # adds 0 to all missing values
test1 <- factorise(test1)
test1$income <- factor(test1$income)
test1$Price1 <- factor(test1$Price1)
test1$Price2 <- factor(test1$Price2)
test1$Price3 <- factor(test1$Price3)
test1$Price4 <- factor(test1$Price4)
test1sub <- subset(test1, select = - c(1,2,3,95,96,97,98))
train_all <- subset(train1, select = - c(1,2,3,95,96,97,98))
modelC45 <- J48(Choice ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test1sub)
predC45 <- predict(modelC45, newdata = test1sub, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
write.csv(predC45, "submissionDay3_2.csv")
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
N <- nrow(prednb1)
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #0.7664536
write.csv(prednb1, "naivebayes.csv")
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
N <- nrow(predC45)
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss #0.7167848
str(train1)
train_all <- subset(train1, select = - c(1,2,3,95,96,97,98))
testoftestnew <- subset(testoftest, select = - c(1,2,3,95,96,97,98))
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
N <- nrow(predC45)
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss #0.7167848
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
N <- nrow(prednb1)
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #0.7664536
write.csv(prednb1, "naivebayes.csv")
library(e1071)
svm1 <- svm(Choice ~ ., data = trainoftrainnew, probability = TRUE)
svm1 <- svm(as.factor(Choice) ~ ., data = trainoftrainnew, probability = TRUE)
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
summary(nb1)
head(prednb1, 1)
sum(prednb1[1,])
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #1.204224
svm1 <- svm(Choice ~ ., data = trainoftrainnew, probability = TRUE)
svm1 <- svm(Choice ~ ., data = trainoftrainnew)
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
library(C50)
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
predC50 <- predict.C5.0(C50model1, newdata = testoftestnew, type = "prob")
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
str(trainoftrainnew)
nb1 <- naiveBayes(Choice ~ ., data = trainoftrain)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #1.204224
modelBag1 <- Bagging(Choice ~ ., data = trainoftrain, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftestnew, type = "probability")
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = testoftestnew, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*testoftest[,95:98]))/N
logloss #1.439258
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftestnew, type = "probability")
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*testoftest[,95:98]))/N
logloss
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew)
prednb1 <- predict(nb1, newdata = testoftestnew, type = "raw")
logloss<- -(sum(log(prednb1)*testoftest[,95:98]))/N
logloss #1.204224
svm1 <- svm(Class ~ ., data = trainoftrainnew, probability = TRUE)
svm1 <- svm(Choice ~ ., data = trainoftrainnew, probability = TRUE)
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
str(trainoftrainnew)
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
rf <- randomForest(Choice ~ ., data = trainoftrainnew, importance = TRUE)
str(trainoftrainnew)
predrf <- predict(rf, newdata = testoftestnew, type = "prob")
head(predrf)
sum(predrf[1,])
N <- nrow(predrf)
logloss<- -(sum(log(predrf)*test_rf[,15:18], na.rm = TRUE))/N
logloss<- -(sum(log(predrf)*testoftest[,15:18], na.rm = TRUE))/N
logloss
logloss<- -(sum(log(predrf)*testoftest[,95:98]))/N
logloss
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnew)
C50model1 <- C5.0(Choice ~ ., data = factor(trainoftrainnew)
C50model1 <- C5.0(Choice ~ ., data = factor(trainoftrainnew))
trainoftrainnewcopy <- trainoftrainnew
trainoftrainnewcopy <- lapply(trainoftrainnewcopy, factor)
str(trainoftrainnewcopy)
C50model1 <- C5.0(Choice ~ ., data = trainoftrainnewcopy)
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnewcopy)
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = testoftestnew, type = "probability")
head(predBag,5)
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*testoftest[,95:98]))/N
logloss #NaN
varImpPlot(rf)
library(e1071)
svm1 <- svm(Choice ~., data = trainoftrainnew)
svm1 <- svm(Choice ~., data = trainoftrainnewcopy)
svm1 <- svm(Choice ~., data = trainoftrainnew)
?naiveBayes
