---
title: "kaggle_car choices"
output: html_document
---
setwd("/Users/fendylieanata/Dropbox/ESD_Term 8/40.220 Analytics Edge/kaggle")


## Functions
```{r}
# convert all income to the middle value
convertincometointeger <- function(train){ 
        train$income <- ifelse(train$income == "Under $29,999", 15000, ifelse(train$income == "$30,000 to $39,999", 35000, ifelse(train$income =="$40,000 to $49,999", 45000, ifelse(train$income =="$50,000 to $59,999", 55000, ifelse(train$income =="$60,000 to $69,999", 65000, ifelse(train$income =="$70,000 to $79,999", 75000, ifelse(train$income =="$80,000 to $89,999", 85000, ifelse(train$income =="$90,000 to $99,999", 95000, ifelse(train$income =="$100,000 to $109,999", 105000, ifelse(train$income == "$110,000 to $119,999", 115000, ifelse(train$income == "$120,000 to $129,999", 125000, ifelse(train$income == "$130,000 to $139,999", 135000, ifelse(train$income == "$140,000 to $149,999", 145000, ifelse(train$income == "$150,000 to $159,999", 155000, ifelse(train$income == "$160,000 to $169,999", 165000, ifelse(train$income == "$170,000 to $179,999", 175000, ifelse(train$income == "$190,000 to $199,999", 195000, ifelse(train$income == "$200,000 to $209,999", 205000, ifelse(train$income == "$220,000 to $229,999", 225000, ifelse(train$income == "$250,000 to $259,999", 255000, ifelse(train$income == "$300,000 & Over", 320000, NA)))))))))))))))))))))
        return (train)
}

# manage inconsistencies in income (only for training)
convertincome_train <- function(train){ 
        for (i in 1:N){
                if (train[i,93] == "$290,000 to $299,999"){
                        train[i,93] <- as.character("$300,000 & Over")
                        }
                }
        return (train)
}
# manage inconsistencies in income (only for test)
convertincome_test <- function(test){
        for (i in 1:N){
          if (as.character(test[i,93]) == "$180,000 to $189,999"){
            test[i,93] = as.character("$170,000 to $179,999")
          } else if (as.character(test[i,93]) == "$230,000 to $239,999"){
            test[i,93] = as.character("$220,000 to $229,999")
          } else if (as.character(test[i,93]) == "$270,000 to $279,999"){
            test[i,93] = as.character("$250,000 to $259,999")
          }
        return (test)
}

}

# factorise the variables (segment, year .. ppark)
factorise <- function(train){
        train$segment <- factor(train$segment)
        train$year <- factor(train$year)
        train$miles <- factor(train$miles)
        train$night <- factor(train$night)
        train$gender <- factor(train$gender)
        train$age <- factor(train$age)
        train$educ <- factor(train$educ)
        train$region <- factor(train$region)
        train$Urb <- factor(train$Urb)
        train$ppark <- factor(train$ppark)
        return (train)
}

```


# training sets
```{r}
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train <- convertincometointeger(convertincome_train(train)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the medium value.
train <- factorise(train) # factorise the variables (segment, year .. ppark)

set.seed(100)
library(caTools)
spl <- sample.split(train$Choice, SplitRatio = 0.7)
train_train <- subset(train, spl == TRUE)
train_test <- subset(train, spl == FALSE)

library(mlogit)
traindata <- mlogit.data(train, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
train_train <- mlogit.data(train_train, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
train_test <- mlogit.data(train_test, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

traindatanew <- subset(traindata, select = - c(1,2,3,15,16,17,18,20,41)) # remove ch1,ch2,ch3,ch4,chid,alt columns

```

### Test Set
```{r}
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
test <- convertincometointeger(convertincome_test(test))
test <- factorise(test)

testdata <- mlogit.data(test, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
testdata[is.na(testdata)] <- 0

testdatanew <- subset(testdata, select = - c(1,2,3,15,16,17,18,20,41)) # remove ch1,ch2,ch3,ch4,chid,alt columns
testdatanew$year <- factor(testdatanew$year)
testdatanew$Choice <- factor(ifelse(testdatanew$Choice == TRUE, 1, 0))
```

### Mlogit
```{r}
# initialise everything
model1 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train)
summary(model1)
AIC(model1) #23645.76, logloss: 1.296198

model2 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch1", data = traindata)
summary(model2)
AIC(model2) #22988.89 1.318158

model3 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch2", data = traindata)
summary(model3)
AIC(model3) #22988.89 1.318158

model4 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch3", data = traindata)
summary(model4)
AIC(model4) #22988.89 1.318158

model5 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch4", data = traindata)
summary(model5)
AIC(model5) #22988.89 1.318158

model6 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, data = traindata)
summary(model6)
AIC(model6) #22988.89, logloss: 1.318158

model7 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | segment + educ + miles + age + region + Urb + ppark + night, data = traindata)
AIC(model7) #22365.67

#kaggle score: 1.23575

# To get the logloss

# To predict test set
predmlogit1 <- predict(model1, newdata = testdata)
N <- nrow(test)
predmlogit1_log <- log(predmlogit1)
logloss1<- -(sum(predmlogit1_log*train[,95:98]))/N
logloss1 #1.348479
write.csv(predmlogit1, "submissionDay2_1.csv")

model8 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | income + segment + educ + miles + age + region + Urb + ppark + night, data = traindata)
AIC(model8) #22310.62

model9 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without FA, RP, FP
summary(model9)
AIC(model9) #23648.36, logloss: 1.296362

model10 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without FP
summary(model10)
AIC(model10) #23645.12, logloss: 1.296008

model11 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without FA
summary(model11)
AIC(model11) #23646.66, logloss: 1.296373

model12 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without RP
summary(model12)
AIC(model12) #23647.31, logloss: 1.296375

modelX <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+I(Price/income)-1 | segment + educ + miles + age + region + Urb + ppark + night + gender + year, data = traindata) #without FP, RP, FA
summary(modelX)
AIC(modelX) #23921.81, logloss: 1.294469 (without FP, without intercept and with RHS), 1.23177 (without FP, with intercept and without RHS), 1.222362 (without FP, without RHS and without intercept), 1.222313 (without FP, RP, FA, without RHS and without intercept), 1.289767 (without FP, RP, FA, with RHS and without intercept)

lrtest(model7, modelX)

predmlogitX <- predict(modelX, newdata = testdata)
head(predmlogitX)
sum(predmlogitX[1,])
N <- nrow(test)
predmlogit_log <- log(predmlogitX)
logloss <- -(sum(predmlogit_log*train[,95:98]))/N
logloss
write.csv(predmlogitX)

coef6 <- as.matrix(coef(model6))

m <- model.matrix(model6)
alt <- index(traindata)$alt
chid <- index(traindata)$chid
eXb <- as.numeric(exp(m %*% coef(model6)))
SeXb <- tapply(eXb, chid, sum)
P <- eXb/SeXb[chid]
P <- matrix(P, ncol = 4, byrow = TRUE)
head(P)
```

```{r}
library(ISLR)
library(leaps)
train.mat <- model.matrix(Choice ~., data = train)
var.length <- ncol(train) - 1
k <- 10
set.seed(100)
folds <- sample(1:k, nrow(train))

hist(train$GN1)
N <- nrow(train)
predictmodel1<-fitted(model1)
predictmodel1_log <- log(predictmodel1)
logloss1<- -(sum(predictmodel1_log*train[,95:98]))/N
logloss1

predictmodel2 <- model1$fitted.values
predictmodel2_log <- log(predictmodel2)
logloss2<- -(sum(predictmodel2_log*train[,95:98]))/N
logloss2
```

### Logistic Regression
```{r}
logreg1 <- glm(Choice ~., data = traindatanew, family = binomial)
summary(logreg1)
predlogreg1 <- predict(logreg1, newdata = testdatanew, type = "response")
N <- nrow(test)
head(predlogreg1)
predlogregmat1 <- matrix(predlogreg1, nrow = N, ncol = 4, byrow = TRUE)
head(predlogregmat1)
sum(predlogregmat1[1,])
for (i in 1:N){
  d <- sum(predlogregmat1[i,])
  for (j in 1:4){
    predlogregmat1[i,j] <- predlogregmat1[i,j]/d
  }
}
sum(predlogregmat1[1,])
predlogregmat1_log <- log(predlogregmat1)
logloss<- -(sum(predlogregmat1_log*train[,95:98]))/N
logloss #1.266619
```

### C5.0
```{r}
#kaggle score: 1.39744
library(C50)
C50model1 <- C5.0(as.factor(Choice) ~ ., data = traindatanew)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = testdatanew, type = "prob")
head(predC50)
N <- nrow(test)
predC50Matrix <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
head(predC50Matrix)
for (i in 1:N){
  d <- sum(predC50Matrix[i,])
  for (j in 1:4){
    predC50Matrix[i,j] <- predC50Matrix[i,j]/d
  }
}
sum(predC50Matrix[1,])
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss #1.29352
write.csv(predC50Matrix, "submission1.csv")

C50model1 <- C5.0(Choice ~ ., data = traindatanew)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix2 <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
predC50Matrix_log <- log(predC50Matrix2)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss

C50model2 <- C5.0(Choice ~ ., data = traindatanew, control = C5.0Control(winnow = TRUE))
predC50 <- predict.C5.0(C50model2, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix<-matrix(predC50[,2],nrow=N,ncol=4,byrow=TRUE)
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss
```

### Random Forest
```{r}
#kaggle score: 1.23523
library(randomForest)
rf1 <- randomForest(Choice ~ ., data = traindatanew, ntree = 1000)
predrf1 <- predict(rf1, newdata = testdatanew, type = "prob")
head(predrf1)
predrf1Matrix <- matrix(predrf1[,2], nrow = N, ncol = 4, byrow = TRUE)
head(predrf1Matrix)
sum(predrf1Matrix[1,])
for (i in 1:N){
  d <- sum(predrf1Matrix[i,])
  for (j in 1:4){
    predrf1Matrix[i,j] <- predrf1Matrix[i,j]/d
  }
}
sum(predrf1Matrix[1,])
predrf1Matrix_log <- log(predrf1Matrix)
head(predrf1Matrix_log)
logloss<- -(sum(predrf1Matrix_log*train[,95:98]))/N
logloss #1.168368
write.csv(predrf1Matrix, "submissionday1_2.csv")

```

```{r}
lev1 = c()
for (i in traindata[0,]){
  lev1 <- c(lev1, levels(i))
}
lev1
lev2 = c()
for (i in testdata[0,]){
  lev2 <- c(lev2, levels(i))
}
lev2

length(lev)
levels("Price")

which(!(levels(test$income) %in% levels(train$income)))
testdata[is.na(testdata)] <- 0

testdata$income <- ifelse(testdata$income == levels(testdata$income)[9], "$170,000 to $179,999", ifelse(testdata$income == levels(testdata$income)[13], "$220,000 to $229,999", ifelse(testdata$income == levels(testdata$income)[15], "$250,000 to $259,999")))
```

#SVM
```{r}

```



