---
title: "kaggle_car choices"
output: html_document
---
setwd("/Users/fendylieanata/Dropbox/ESD_Term 8/40.220 Analytics Edge/kaggle")
setwd("~/Dropbox/SUTD/LECTURE NOTES/Term 8/Analytics wd/Kaggle/kaggle")
## Functions
```{r}
# convert all income to the middle value
convertincometointeger <- function(train){ 
        train$income <- ifelse(train$income == "Under $29,999", 15000, ifelse(train$income == "$30,000 to $39,999", 35000, ifelse(train$income =="$40,000 to $49,999", 45000, ifelse(train$income =="$50,000 to $59,999", 55000, ifelse(train$income =="$60,000 to $69,999", 65000, ifelse(train$income =="$70,000 to $79,999", 75000, ifelse(train$income =="$80,000 to $89,999", 85000, ifelse(train$income =="$90,000 to $99,999", 95000, ifelse(train$income =="$100,000 to $109,999", 105000, ifelse(train$income == "$110,000 to $119,999", 115000, ifelse(train$income == "$120,000 to $129,999", 125000, ifelse(train$income == "$130,000 to $139,999", 135000, ifelse(train$income == "$140,000 to $149,999", 145000, ifelse(train$income == "$150,000 to $159,999", 155000, ifelse(train$income == "$160,000 to $169,999", 165000, ifelse(train$income == "$170,000 to $179,999", 175000, ifelse(train$income == "$190,000 to $199,999", 195000, ifelse(train$income == "$200,000 to $209,999", 205000, ifelse(train$income == "$220,000 to $229,999", 225000, ifelse(train$income == "$250,000 to $259,999", 255000, ifelse(train$income == "$300,000 & Over", 320000, NA)))))))))))))))))))))
        return (train)
}

convertpricetointeger <- function(train){ 
        train <- ifelse(train == 1, 500, ifelse(train == 2, 1000, ifelse(train ==3, 1500, ifelse(train == 4, 2000, ifelse(train == 5, 2500, ifelse(train == 6, 3000, ifelse(train == 7, 4000, ifelse(train == 8, 5000, ifelse(train == 9, 7500, ifelse(train == 10, 10000, ifelse(train == 11, 12000, 1)))))))))))
        return (train)
}

# manage inconsistencies in income (only for training)
convertincome_train <- function(train){
        N <- nrow(train)
        for (i in 1:N){
                if (train[i,93] == "$290,000 to $299,999"){
                        train[i,93] <- as.character("$300,000 & Over")
                        }
                }
        return (train)
}

# manage inconsistencies in income (only for test)
convertincome_test <- function(test){
        N <- nrow(test)
        for (i in 1:N){
          if (as.character(test[i,93]) == "$180,000 to $189,999"){
            test[i,93] = as.character("$170,000 to $179,999")
          } else if (as.character(test[i,93]) == "$230,000 to $239,999"){
            test[i,93] = as.character("$220,000 to $229,999")
          } else if (as.character(test[i,93]) == "$270,000 to $279,999"){
            test[i,93] = as.character("$250,000 to $259,999")
          }
        return (test)
        }
}

# factorise the variables (segment, year .. ppark)
factorise <- function(train){
        train$segment <- factor(train$segment)
        train$year <- factor(train$year)
        train$miles <- factor(train$miles)
        train$night <- factor(train$night)
        train$gender <- factor(train$gender)
        train$age <- factor(train$age)
        train$educ <- factor(train$educ)
        train$region <- factor(train$region)
        train$Urb <- factor(train$Urb)
        train$ppark <- factor(train$ppark)
        return (train)
}

```


# Training sets
```{r}
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train <- convertincometointeger(convertincome_train(train)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
train <- factorise(train) # factorise the variables (segment, year .. ppark)
train$Price1 <- convertpricetointeger(train$Price1)
train$Price2 <- convertpricetointeger(train$Price2)
train$Price3 <- convertpricetointeger(train$Price3)
train$Price4 <- convertpricetointeger(train$Price4)

set.seed(100)
library(caTools)
spl <- sample.split(train$Choice, SplitRatio = 0.7)
train_train <- subset(train, spl == TRUE)
train_test <- subset(train, spl == FALSE)

library(mlogit)
traindata <- mlogit.data(train, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
train_train <- mlogit.data(train_train, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
train_test <- mlogit.data(train_test, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

traindatanew <- subset(traindata, select = - c(1,2,3,15,16,17,18,20,41)) # remove ch1,ch2,ch3,ch4,chid,alt columns

```

### Test sets
```{r}
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test[is.na(test)] <- 0 # adds 0 to all missing values
test <- convertincometointeger(convertincome_test(test))
test <- factorise(test)
test$Price1 <- convertpricetointeger(test$Price1)
test$Price2 <- convertpricetointeger(test$Price2)
test$Price3 <- convertpricetointeger(test$Price3)
test$Price4 <- convertpricetointeger(test$Price4)

testdata <- mlogit.data(test, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

#testdatanew$year <- factor(testdatanew$year)
#testdatanew$Choice <- factor(ifelse(testdatanew$Choice == TRUE, 1, 0))
#testdatanew <- subset(testdata, select = - c(1,2,3,15,16,17,18,20,41)) # remove ch1,ch2,ch3,ch4,chid,alt columns
```

### Mlogit
```{r}
# initialise everything
model1 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train)
summary(model1)
AIC(model1) #16632.11, LL: -8296.1, logloss: 1.548816

model2 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch1", data = train_train)
summary(model2)
AIC(model2) #16138.74, LL: -8046.4, logloss: 1.599684

model3 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch2", data = train_train)
summary(model3)
AIC(model3) #16138.74, LL: -8046.4, logloss: 1.599684

model4 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch3", data = train_train)
summary(model4)
AIC(model4) #16138.74, LL: -8046.4, logloss: 1.599684

model5 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, reflevel = "Ch4", data = train_train)
summary(model5)
AIC(model5) #16138.74, LL: -8046.4, logloss: 1.599684

model6 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, data = train_train)
summary(model6)
AIC(model6) #16138.74, LL: -8046.4, logloss: 1.599684

model7 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | segment + educ + miles + age + region + Urb + ppark + night + gender + year, data = train_train)
summary(model7)
AIC(model7) #15705.3, LL: -7685.7, logloss: 1.668882 #kaggle score: 1.23575 #write.csv(predmlogit1, "submissionDay2_1.csv")

model8 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FA, RP, FP
summary(model8)
AIC(model8) #16631.87, LL:-8298.9, logloss: 1.548005

model9 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP
summary(model9)
AIC(model9) #16631.24, LL:-8296.6, logloss: 1.548661

model10 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FA
summary(model10)
AIC(model10) #16631.3, LL:-8296.6, logloss: 1.5486

model11 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without RP
summary(model11)
AIC(model11) #16633.07, LL:-8297.5, logloss: 1.548446

model12 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP, FA
summary(model12)
AIC(model12) #16630.52, LL:--8297.3, logloss: 1.548433

model13 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP, RP
summary(model13)
AIC(model13) #16632.32, LL:-8298.2, logloss: 1.548278

model14 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+FP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FA, RP
summary(model14)
AIC(model14) #16632.49, LL:-8298.2, logloss: 1.548186

model15 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+I(Price/income)-1 | segment + educ + miles + age + region + Urb + ppark + night + gender + year, data = train_train)
summary(model15)
AIC(model15) #16807.14, LL:-8236.6, logloss: 1.572323

model16 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+I(Price/income)-1, data = train_train)
summary(model16)
AIC(model16) #17923.94, LL: -8942, logloss: 1.438996

model17 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+I(Price/income)-1, data = train_train)
summary(model17)
AIC(model17) #17923.54, LL: -8944.8, logloss: 1.438956 #kaggle score: 1.44686

model18 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, rpar = c(CC="n", GN = "n", NS = "n", BU = "n", LD = "n", BZ = "n", FC = "n", PP = "n", KA = "n", SC = "n", TS = "n", NV = "n", MA = "n", LB = "n", AF = "n", HU = "n", Price = "n"), panel = TRUE, data = train_train)
summary(model18)
AIC(model18) #14178.18, LL: -7055.1, logloss: 1.577168

model19 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, rpar = c(CC="t", GN = "t", NS = "t", BU = "t", LD = "t", BZ = "t", FC = "t", PP = "t", KA = "t", SC = "t", TS = "t", NV = "t", MA = "t", LB = "t", AF = "t", HU = "t", Price = "t"), panel = TRUE, data = train_train)
summary(model19)
AIC(model19) #14425.72, LL:-7178.9, logloss: 1.588533

model20 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, rpar = c(CC="u", GN = "u", NS = "u", BU = "u", LD = "u", BZ = "u", FC = "u", PP = "u", KA = "u", SC = "u", TS = "u", NV = "u", MA = "u", LB = "u", AF = "u", HU = "u", Price = "n"), panel = TRUE, data = train_train)
summary(model20)
AIC(model20) # 14184.82, LL: -7058.4, logloss: 1.579497

modelX <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, rpar = c(CC="u", GN = "u", NS = "u", BU = "u", LD = "u", BZ = "u", FC = "u", PP = "u", KA = "u", SC = "u", TS = "u", NV = "u", MA = "u", LB = "u", AF = "u", HU = "u", Price = "n"), panel = TRUE, data = train_train)
summary(modelX)
AIC(modelX)

predmlogitX <- predict(modelX, newdata = train_test)
dim(predmlogitX)
sum(predmlogitX[1,])
N <- nrow(train_test)
predmlogit_log <- log(predmlogitX)
logloss <- -(sum(predmlogit_log*train_test[,15:18]))/N
logloss

```

```{r}
m <- model.matrix(model6)
alt <- index(traindata)$alt
chid <- index(traindata)$chid
eXb <- as.numeric(exp(m %*% coef(model6)))
SeXb <- tapply(eXb, chid, sum)
P <- eXb/SeXb[chid]
P <- matrix(P, ncol = 4, byrow = TRUE)
head(P)
```

```{r}
library(ISLR)
library(leaps)
train.mat <- model.matrix(Choice ~., data = train)
var.length <- ncol(train) - 1
k <- 10
set.seed(100)
folds <- sample(1:k, nrow(train))

hist(train$GN1)
N <- nrow(train)
predictmodel1<-fitted(model1)
predictmodel1_log <- log(predictmodel1)
logloss1<- -(sum(predictmodel1_log*train[,95:98]))/N
logloss1

predictmodel2 <- model1$fitted.values
predictmodel2_log <- log(predictmodel2)
logloss2<- -(sum(predictmodel2_log*train[,95:98]))/N
logloss2
```

### Logistic Regression
```{r}
logreg1 <- glm(Choice ~., data = traindatanew, family = binomial)
summary(logreg1)
predlogreg1 <- predict(logreg1, newdata = testdatanew, type = "response")
N <- nrow(test)
head(predlogreg1)
predlogregmat1 <- matrix(predlogreg1, nrow = N, ncol = 4, byrow = TRUE)
head(predlogregmat1)
sum(predlogregmat1[1,])
for (i in 1:N){
  d <- sum(predlogregmat1[i,])
  for (j in 1:4){
    predlogregmat1[i,j] <- predlogregmat1[i,j]/d
  }
}
sum(predlogregmat1[1,])
predlogregmat1_log <- log(predlogregmat1)
logloss<- -(sum(predlogregmat1_log*train[,95:98]))/N
logloss #1.266619
```

### C5.0
```{r}
#kaggle score: 1.39744
library(C50)
C50model1 <- C5.0(as.factor(Choice) ~ ., data = traindatanew)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = testdatanew, type = "prob")
head(predC50)
N <- nrow(test)
predC50Matrix <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
head(predC50Matrix)
for (i in 1:N){
  d <- sum(predC50Matrix[i,])
  for (j in 1:4){
    predC50Matrix[i,j] <- predC50Matrix[i,j]/d
  }
}
sum(predC50Matrix[1,])
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss #1.29352
write.csv(predC50Matrix, "submission1.csv")

C50model1 <- C5.0(Choice ~ ., data = traindatanew)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix2 <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
predC50Matrix_log <- log(predC50Matrix2)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss

C50model2 <- C5.0(Choice ~ ., data = traindatanew, control = C5.0Control(winnow = TRUE))
predC50 <- predict.C5.0(C50model2, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix<-matrix(predC50[,2],nrow=N,ncol=4,byrow=TRUE)
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss
```

### Random Forest
```{r}
#kaggle score: 1.23523
library(randomForest)
rf1 <- randomForest(Choice ~ ., data = traindatanew, importance = TRUE)
predrf1 <- predict(rf1, newdata = testdatanew, type = "prob")
head(predrf1)
predrf1Matrix <- matrix(predrf1[,2], nrow = N, ncol = 4, byrow = TRUE)
head(predrf1Matrix)
sum(predrf1Matrix[1,])
for (i in 1:N){
  d <- sum(predrf1Matrix[i,])
  for (j in 1:4){
    predrf1Matrix[i,j] <- predrf1Matrix[i,j]/d
  }
}
sum(predrf1Matrix[1,])
predrf1Matrix_log <- log(predrf1Matrix)
head(predrf1Matrix_log)
logloss<- -(sum(predrf1Matrix_log*train[,95:98]))/N
logloss #1.168368
write.csv(predrf1Matrix, "submissionday1_2.csv")

```

```{r}
lev1 = c()
for (i in traindata[0,]){
  lev1 <- c(lev1, levels(i))
}
lev1
lev2 = c()
for (i in testdata[0,]){
  lev2 <- c(lev2, levels(i))
}
lev2

length(lev)
levels("Price")

which(!(levels(test$income) %in% levels(train$income)))
testdata[is.na(testdata)] <- 0

testdata$income <- ifelse(testdata$income == levels(testdata$income)[9], "$170,000 to $179,999", ifelse(testdata$income == levels(testdata$income)[13], "$220,000 to $229,999", ifelse(testdata$income == levels(testdata$income)[15], "$250,000 to $259,999")))
```

### Output
```{r}
modelY <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata)
predmlogitX <- predict(modelY, newdata = testdata)
dim(predmlogitX) # 11951 by 4       why?
sum(predmlogitX[1,])
write.csv(predmlogitX, "submissionDay2_2x.csv")
```


#Neural networks
```{r}

trainNN <- (cbind(train[,4:83],train[99]))
# trainNN$Choice <- as.character(trainNN$Choice)
# trainNN$Choice[trainNN$Choice=="Ch1"]<-1
# trainNN$Choice[trainNN$Choice=="Ch2"]<-2
# trainNN$Choice[trainNN$Choice=="Ch3"]<-3
# trainNN$Choice[trainNN$Choice=="Ch4"]<-4
# trainNN$Choice <- as.integer(trainNN$Choice)
testNN <- test[,4:83]
set.seed(100)
model <- train(Choice~., data=trainNN, method='nnet',trControl=trainControl(method='cv'))
model
probs <- predict(model, type='prob')
compute(model, testNN)$model.result
head(probs)
write.table(probs,file="nn.csv",sep=",",row.names=FALSE)
# net <- neuralnet(Choice~CC1+GN1+NS1+BU1+LD1+BZ1+FC1+PP1+KA1+SC1+TS1+NV1+MA1+LB1+AF1+HU1+Price1+
#                         CC2+GN2+NS2+BU2+LD2+BZ2+FC2+PP2+KA2+SC2+TS2+NV2+MA2+LB2+AF2+HU2+Price2+
#                         CC3+GN3+NS3+BU3+LD3+BZ3+FC3+PP3+KA3+SC3+TS3+NV3+MA3+LB3+AF3+HU3+Price3+
#                         CC4+GN4+NS4+BU4+LD4+BZ4+FC4+PP4+KA4+SC4+TS4+NV4+MA4+LB4+AF4+HU4+Price4,trainNN, hidden=0, rep=10, err.fct="sse", linear.output=FALSE)
# net
# compute(net, (1:10)^2)$net.result

# require(caret)
# model <- train(Species~., data=iris, method='nnet', 
#                trControl=trainControl(method='cv'))
# model
# probs <- predict(model, newdata=testNN, type='prob')
# head(probs)

```

