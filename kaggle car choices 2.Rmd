---
title: "kaggle_car choices"
output: html_document
---
setwd("/Users/fendylieanata/Dropbox/ESD_Term 8/40.220 Analytics Edge/kaggle")
setwd("~/Dropbox/SUTD/LECTURE NOTES/Term 8/Analytics wd/Kaggle/kaggle")
## Functions
```{r}
# convert all income to the middle value
convertincometointeger <- function(train){ 
        train$income <- ifelse(train$income == "Under $29,999", 15000, ifelse(train$income == "$30,000 to $39,999", 35000, ifelse(train$income =="$40,000 to $49,999", 45000, ifelse(train$income =="$50,000 to $59,999", 55000, ifelse(train$income =="$60,000 to $69,999", 65000, ifelse(train$income =="$70,000 to $79,999", 75000, ifelse(train$income =="$80,000 to $89,999", 85000, ifelse(train$income =="$90,000 to $99,999", 95000, ifelse(train$income =="$100,000 to $109,999", 105000, ifelse(train$income == "$110,000 to $119,999", 115000, ifelse(train$income == "$120,000 to $129,999", 125000, ifelse(train$income == "$130,000 to $139,999", 135000, ifelse(train$income == "$140,000 to $149,999", 145000, ifelse(train$income == "$150,000 to $159,999", 155000, ifelse(train$income == "$160,000 to $169,999", 165000, ifelse(train$income == "$170,000 to $179,999", 175000, ifelse(train$income == "$190,000 to $199,999", 195000, ifelse(train$income == "$200,000 to $209,999", 205000, ifelse(train$income == "$220,000 to $229,999", 225000, ifelse(train$income == "$250,000 to $259,999", 255000, ifelse(train$income == "$300,000 & Over", 320000, NA)))))))))))))))))))))
        return (train)
}

convertpricetointeger <- function(train){ 
        train <- ifelse(train == 1, 500, ifelse(train == 2, 1000, ifelse(train ==3, 1500, ifelse(train == 4, 2000, ifelse(train == 5, 2500, ifelse(train == 6, 3000, ifelse(train == 7, 4000, ifelse(train == 8, 5000, ifelse(train == 9, 7500, ifelse(train == 10, 10000, ifelse(train == 11, 12000, 1)))))))))))
        return (train)
}

# manage inconsistencies in income (only for training)
convertincome_train <- function(object){
        N <- nrow(object)
        for (i in 1:N){
                if (object[i,93] == "$290,000 to $299,999"){
                        object[i,93] <- as.character("$300,000 & Over")
                        print ("converted!")
                        }
                }
        return (object)
}

# manage inconsistencies in income (only for test)
convertincome_test <- function(object){
        N <- nrow(object)
        for (i in 1:N){
          if (object[i,93] == "$180,000 to $189,999"){
            object[i,93] <- as.character("$170,000 to $179,999")
            print ("converted!")
          } else {
            if (object[i,93] == "$230,000 to $239,999"){
              object[i,93] <- "$220,000 to $229,999"
              print ("converted!")
            } else {
              if (object[i,93] == "$270,000 to $279,999"){
                object[i,93] <- ("$250,000 to $259,999")
                print ("converted")
              }
            }
          }
        }
        return (object)
}

# factorise the variables (segment, year .. ppark)
factorise <- function(train){
        train$segment <- factor(train$segment)
        train$year <- factor(train$year)
        train$miles <- factor(train$miles)
        train$night <- factor(train$night)
        train$gender <- factor(train$gender)
        train$age <- factor(train$age)
        train$educ <- factor(train$educ)
        train$region <- factor(train$region)
        train$Urb <- factor(train$Urb)
        train$ppark <- factor(train$ppark)
        return (train)
}

```

# Preparing Training sets
```{r}
train <- read.csv("train.csv", stringsAsFactors = FALSE)
train1 <- convertincometointeger(convertincome_train(train)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
train1 <- factorise(train1) # factorise the variables (segment, year .. ppark)
train1$Price1 <- convertpricetointeger(train1$Price1)
train1$Price2 <- convertpricetointeger(train1$Price2)
train1$Price3 <- convertpricetointeger(train1$Price3)
train1$Price4 <- convertpricetointeger(train1$Price4)
train1$Choice <- factor(train1$Choice)

library(mlogit)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainmlogit <- train
trainmlogit <- convertincome_train(trainmlogit)

trainmlogit_train <- subset(trainmlogit, Task<=8)
trainmlogit_test <- subset(trainmlogit, Task>8)

trainmlogit_trainmlogit <- mlogit.data(trainmlogit_train, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

trainmlogit_testmlogit <- mlogit.data(trainmlogit_test, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainmlogit <- train
trainmlogit <- convertincome_train(trainmlogit)
set.seed(100)
library(caTools)
spl <- sample.split(trainmlogit$Choice, SplitRatio = 0.4)
trainmlogit_trainrand <- subset(trainmlogit, spl==TRUE)
trainmlogit_testrand <- subset(trainmlogit, spl==FALSE)

trainmlogit_trainrandmlogit <- mlogit.data(trainmlogit_trainrand, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

trainmlogit_testrandmlogit <- mlogit.data(trainmlogit_testrand, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

trainmlogit_mlogit <- mlogit.data(trainmlogit, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

```

### Preparing Test sets
```{r}
test <- read.csv("test.csv", stringsAsFactors = FALSE)
test1 <- test
test1[is.na(test1)] <- 0 # adds 0 to all missing values
#test1 <- convertincometointeger(convertincome_test(test1))
#test1 <- factorise(test1)
#test1$Price1 <- convertpricetointeger(test1$Price1)
#test1$Price2 <- convertpricetointeger(test1$Price2)
#test1$Price3 <- convertpricetointeger(test1$Price3)
#test1$Price4 <- convertpricetointeger(test1$Price4)
#test1$Choice <- factor(test1$Choice)

#mlogit
test <- read.csv("test.csv", stringsAsFactors = FALSE)
testmlogit <- test
testmlogit[is.na(testmlogit)] <- 0 # adds 0 to all missing values
testmlogit <- convertincome_test(testmlogit)
testmlogit_mlogit <- mlogit.data(testmlogit, shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")

#testdatanew$year <- factor(testdatanew$year)
#testdatanew$Choice <- factor(ifelse(testdatanew$Choice == TRUE, 1, 0))
#testdatanew <- subset(testdata, select = - c(1,2,3,15,16,17,18,20,41)) # remove ch1,ch2,ch3,ch4,chid,alt columns
```

### Mlogit
```{r}
# initialise everything
model1 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU | income + segment + miles + educ + age + region + Urb + ppark + night , data = trainmlogit_trainmlogit)
summary(model1)
AIC(model1) #16632.11, LL: -8296.1, logloss: 1.296198 

model6 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price, data = traindata)
summary(model6)
AIC(model6) #16138.74, LL: -8046.4, logloss: 1.318158

model7 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | income + segment + educ + miles + age + Urb + ppark + night + gender, data = trainmlogit_trainmlogit)
summary(model7)
AIC(model7) #15705.3, LL: -7685.7, logloss: 1.179093 (with Price as int) #kaggle score: 1.23575 #write.csv(predmlogit1, "submissionDay2_1.csv")

model8 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without FA, RP, FP
summary(model8)
AIC(model8) #16631.87, LL:-8298.9, logloss: 1.548005, 1.232115 (with Price as int)

model9 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP
summary(model9)
AIC(model9) #16631.24, LL:-8296.6, logloss: 1.548661

model10 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata) #without FA
summary(model10)
AIC(model10) #16631.3, LL:-8296.6, logloss: 1.5486

model11 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without RP
summary(model11)
AIC(model11) #16633.07, LL:-8297.5, logloss: 1.548446

model12 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP, FA
summary(model12)
AIC(model12) #16630.52, LL:--8297.3, logloss: 1.548433

model13 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FP, RP
summary(model13)
AIC(model13) #16632.32, LL:-8298.2, logloss: 1.548278

model14 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+FP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = train_train) #without FA, RP
summary(model14)
AIC(model14) #16632.49, LL:-8298.2, logloss: 1.548186

model17 <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+I(Price/income)-1, data = train_train)
summary(model17)
AIC(model17) #17923.54, LL: -8944.8, logloss: 1.438956 #kaggle score: 1.44686

model7 <- mlogit(Choice ~ CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | income + segment + educ + age + region + Urb + ppark + gender , data = trainmlogit_trainrandmlogit)
predmlogitX <- predict(model7, newdata = trainmlogit_testrandmlogit)
-(sum(log(predmlogitX)*trainmlogit_testrand[,95:98]))/nrow(predmlogitX)
#BU+FA+BZ+FC+FP+AF+HU+Price

#FA1+BZ1+FC1+FP1+HU1+Price1+AF1+BU1+  income + segment + miles + age + region + Urb + ppark
modelX <- mlogit(Choice ~ GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | segment + miles + region + Urb + ppark, data = trainmlogit_trainrandmlogit)
predmlogitX <- predict(modelX, newdata = trainmlogit_testrandmlogit)
-(sum(log(predmlogitX)*trainmlogit_testrand[,95:98]))/nrow(predmlogitX)

summary(modelX)
AIC(modelX)
#CC+NS+BU+LD+PP+KA+SC+TS+MA+Price

dim(predmlogitX)
sum(predmlogitX[1,])
#submission9: modelY <- mnlogit(Choice ~ CC+BU+KA+SC+TS+Price | income + segment + miles + educ + age + region + Urb + ppark + night + gender, ncores = 2, data = trainmlogit_mlogit)
#submission10: modelY <- mlogit(Choice ~ CC+GN+NS+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+HU+Price | income + segment + miles + age + region + Urb + ppark, data = trainmlogit_mlogit)

modelY <- mlogit(Choice ~ GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price | segment + miles + age + region + Urb + ppark, data = trainmlogit_mlogit)
predmodelY <- predict(modelY, newdata = testmlogit_mlogit)
head(predmodelY,38)
write.csv(predmodelY, "bestmlogit3.csv")
```

### Logistic Regression
```{r}
logreg1 <- glm(Choice ~., data = trainoftrainnew, family = binomial)
summary(logreg1)
predlogreg1 <- predict(logreg1, newdata = testdatanew, type = "response")
N <- nrow(test)
head(predlogreg1)
predlogregmat1 <- matrix(predlogreg1, nrow = N, ncol = 4, byrow = TRUE)
head(predlogregmat1)
sum(predlogregmat1[1,])
for (i in 1:N){
  d <- sum(predlogregmat1[i,])
  for (j in 1:4){
    predlogregmat1[i,j] <- predlogregmat1[i,j]/d
  }
}
sum(predlogregmat1[1,])
predlogregmat1_log <- log(predlogregmat1)
logloss<- -(sum(predlogregmat1_log*train[,95:98]))/N
logloss #1.266619
```

### Modified Data
```{r}
traindata$Class <- 0
for (i in 1:38000){
  for (j in 15:18){
    if (traindata[i,j] == 1){
      traindata[i,]$Class <- colnames(traindata[j])
    } 
  }
}
#write.csv(traindata, "traindata.csv")

testdata$Class <- 0
traindata <- read.csv("traindata.csv")
traindata$Class <- factor(traindata$Class)
traindata$year <- factor(traindata$year)

library(caTools)
spl <- sample.split(traindata$Class, SplitRatio = 0.7)
train_train <- subset(traindata, spl == TRUE)
train_test <- subset(traindata, spl == FALSE)

train_trainnew <- subset(train_train, select = - c(1,2,3,4,16,17,18,19,20,21,42)) # remove ch1,ch2,ch3,ch4,chid,alt columns

train_testnew <- subset(train_test, select = - c(1,2,3,4,16,17,18,19,20,21,42)) # remove ch1,ch2,ch3,ch4,chid,alt columns
```

### C5.0
```{r}
#kaggle score: 1.39744
library(C50)
trainmlogit_mlogit1 <- subset(trainmlogit_mlogit, )
C50model1 <- C5.0(as.factor(Choice) ~ ., data = trainmlogit_mlogit)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = testoftestnew, type = "prob")
head(predC50)
N <- nrow(predC50)
logloss<- -(sum(log(predC50)*train_testnew[,16:19]))/N
logloss


predC50Matrix <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
head(predC50Matrix)
for (i in 1:N){
  d <- sum(predC50Matrix[i,])
  for (j in 1:4){
    predC50Matrix[i,j] <- predC50Matrix[i,j]/d
  }
}
sum(predC50Matrix[1,])
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss #1.29352
write.csv(predC50Matrix, "submission1.csv")

C50model1 <- C5.0(Choice ~ ., data = traindatanew)
C5imp(C50model1)
predC50 <- predict.C5.0(C50model1, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix2 <- matrix(predC50[,2], nrow = N, ncol = 4, byrow = TRUE)
predC50Matrix_log <- log(predC50Matrix2)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss

C50model2 <- C5.0(Choice ~ ., data = traindatanew, control = C5.0Control(winnow = TRUE))
predC50 <- predict.C5.0(C50model2, newdata = traindatanew, type = "prob")
N <- nrow(train)
predC50Matrix<-matrix(predC50[,2],nrow=N,ncol=4,byrow=TRUE)
predC50Matrix_log <- log(predC50Matrix)
logloss<- -(sum(predC50Matrix_log*train[,95:98]))/N
logloss
```

### Random Forest
```{r}
#kaggle score: 1.23523
library(randomForest)
rf <- randomForest(Choice ~ ., data = train_allnew, importance = TRUE, ntree = 2000)
predrf <- predict(rf, newdata = test_allnew, type = "prob")
head(predrf)
sum(predrf[1,])
N <- nrow(predrf)
logloss<- -(sum(log(predrf)*trainoftest[,95:98]))/N
logloss #1.215535 (500 trees), 1.214124 (2000 trees)

rf1 <- randomForest(Choice ~ ., data = trainoftrainnew, importance = TRUE, cutoff=c(0.23,0.25,0.225,0.295))
predrf1 <- predict(rf1, newdata = trainoftestnew, type = "prob")
head(predrf1)
sum(predrf1[1,])
N <- nrow(predrf1)
logloss<- -(sum(log(predrf1)*trainoftest[,95:98]))/N
logloss #1.215535 (500 trees), 1.214124 (2000 trees)

#predrf1Matrix <- matrix(predrf1[,2], nrow = N, ncol = 4, byrow = TRUE)
#head(predrf1Matrix)
#sum(predrf1Matrix[1,])
for (i in 1:N){
  d <- sum(predrf1Matrix[i,])
  for (j in 1:4){
    predrf1Matrix[i,j] <- predrf1Matrix[i,j]/d
  }
}
sum(predrf1Matrix[1,])
predrf1Matrix_log <- log(predrf1Matrix)
head(predrf1Matrix_log)
logloss<- -(sum(predrf1Matrix_log*train[,95:98]))/N
logloss #1.168368
#write.csv(predrf1Matrix, "submissionday1_2.csv")

```

```{r}
which(!(levels(test$income) %in% levels(train$income)))
```

### Output
```{r}
modelY <- mlogit(Choice ~ CC+GN+NS+BU+LD+BZ+FC+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data = traindata)
predmlogitX <- predict(modelY, newdata = testdata)
dim(predmlogitX) # 11951 by 4       why?
sum(predmlogitX[1,])
write.csv(predmlogitX, "submissionDay2_2x.csv")
```

#Neural networks
```{r}
# kaggle score: 1.24106
library(caret)
trainNN <- (cbind(train[,4:83],train[99]))
# trainNN$Choice <- as.character(trainNN$Choice)
# trainNN$Choice[trainNN$Choice=="Ch1"]<-1
# trainNN$Choice[trainNN$Choice=="Ch2"]<-2
# trainNN$Choice[trainNN$Choice=="Ch3"]<-3
# trainNN$Choice[trainNN$Choice=="Ch4"]<-4
# trainNN$Choice <- as.integer(trainNN$Choice)
testNN <- test[,4:83]
set.seed(100)
model <- train(Choice~., data=trainNN, method='nnet',trControl=trainControl(method='cv'))
model
probs1 <- predict(model, newdata=testNN, type='prob')
# compute(model, testNN)$model.result
head(probs1)
write.table(probs,file="nn.csv",sep=",",row.names=FALSE)

# Testing nia.........~~~~~~~~~~~~
train_trainNN <- (cbind(train_train[,4:83],train_train[99]))
train_trainNN$Choice <- as.factor(train_trainNN$Choice)
train_testNN <- (cbind(train_test[,4:83]))
model_traintrain <- train(Choice~., data=train_trainNN, method='nnet',trControl=trainControl(method='cv'))
model_traintrain
probs2 <- predict(model_traintrain, newdata=train_testNN, type='prob')
# compute(model_traintrain, train_testNN)$model_traintrain.result
head(probs2)








# net <- neuralnet(Choice~CC1+GN1+NS1+BU1+LD1+BZ1+FC1+PP1+KA1+SC1+TS1+NV1+MA1+LB1+AF1+HU1+Price1+
#                         CC2+GN2+NS2+BU2+LD2+BZ2+FC2+PP2+KA2+SC2+TS2+NV2+MA2+LB2+AF2+HU2+Price2+
#                         CC3+GN3+NS3+BU3+LD3+BZ3+FC3+PP3+KA3+SC3+TS3+NV3+MA3+LB3+AF3+HU3+Price3+
#                         CC4+GN4+NS4+BU4+LD4+BZ4+FC4+PP4+KA4+SC4+TS4+NV4+MA4+LB4+AF4+HU4+Price4,trainNN, hidden=0, rep=10, err.fct="sse", linear.output=FALSE)
# net
# compute(net, (1:10)^2)$net.result

# require(caret)
# model <- train(Species~., data=iris, method='nnet', 
#                trControl=trainControl(method='cv'))
# model
# probs <- predict(model, newdata=testNN, type='prob')
# head(probs)

```

###C4.5
```{r}
library(RWeka)
library(FSelector)
train <- read.csv("train.csv", stringsAsFactors = FALSE)

## Train 2 1.228622
train2 <- train
train2 <- factorise(train2)
train2 <- convertincometointeger(convertincome_train(train2)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
train2$Choice <- factor(train2$Choice)
train2$income <- factor(train2$income)
train2$Price1 <- factor(train2$Price1)
train2$Price2 <- factor(train2$Price2)
train2$Price3 <- factor(train2$Price3)
train2$Price4 <- factor(train2$Price4)

#train1 <- convertpricetointeger(train1)
#train1 <- convertincometointeger(train1)
set.seed(100)
spl <- sample.split(train2$Choice, SplitRatio = 0.7)
trainoftrain <- subset(train2, spl == TRUE)
trainoftest <- subset(train2, spl == FALSE)
trainoftrainnew <- subset(trainoftrain, select = - c(1,2,3,95,96,97,98))
trainoftestnew <- subset(trainoftest, select = - c(1,2,3,95,96,97,98))

##Train 1 1.761195
train_trainnew <- subset(train_train, select = - c(1,2,3,95,96,97,98 ))
train_testnew <- subset(train_test, select = - c(1,2,3,95,96,97,98 ))

## Train3 1.242267, 1.242426
train3 <- train
train3 <- convertincometointeger(convertincome_train(train3)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
set.seed(100)
spl <- sample.split(train3$Choice, SplitRatio = 0.7)
trainoftrain3 <- subset(train3, spl == TRUE)
trainoftest3 <- subset(train3, spl == FALSE)
trainoftrainnew3 <- subset(trainoftrain3, select = - c(1,2,3,95,96,97,98))
trainoftestnew3 <- subset(trainoftest3, select = - c(1,2,3,95,96,97,98))

trainoftrainnew3fac <- as.data.frame(lapply(trainoftrainnew3, factor))
trainoftestnew3fac <- as.data.frame(lapply(trainoftestnew3, factor))

##Train 4 LHS 1.271868
train4 <- train
set.seed(100)
spl <- sample.split(train4$Choice, SplitRatio = 0.7)
trainoftrain4 <- subset(train4, spl == TRUE)
trainoftest4 <- subset(train4, spl == FALSE)
trainoftrainnew4 <- subset(trainoftrain4, select = - c(1,2,3,84:98))
trainoftestnew4 <- subset(trainoftest4, select = - c(1,2,3,84:98))

trainoftrainnew4fac <- as.data.frame(lapply(trainoftrainnew4, factor))
trainoftestnew4fac <- as.data.frame(lapply(trainoftestnew4, factor))

#Train 5 RHS 1.367065, 1.36721
train5 <- train
train5 <- convertincometointeger(convertincome_train(train5)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
set.seed(100)
spl <- sample.split(train5$Choice, SplitRatio = 0.7)
trainoftrain5 <- subset(train5, spl == TRUE)
trainoftest5 <- subset(train5, spl == FALSE)
trainoftrainnew5 <- subset(trainoftrain5, select = - c(1:83,95:98))
trainoftestnew5 <- subset(trainoftest5, select = - c(1:83,95:98))

#trainoftrainnew5$year <- as.character(trainoftrainnew5$year)
#trainoftestnew5$year <- as.character(trainoftestnew5$year)


trainoftrainnew5fac <- as.data.frame(lapply(trainoftrainnew5, factor))
trainoftestnew5fac <- as.data.frame(lapply(trainoftestnew5, factor))

#Train 6 1.367065
train6 <- train
train6.1 <- lapply(train6[4:63], factor)
train6.2 <- lapply(train6[84:99], factor)
train6.3 <- train[,64:83]
train6 <- cbind(as.data.frame(train6.1), as.data.frame(train6.3), as.data.frame(train6.2))
#train1 <- convertpricetointeger(train1)
#train1 <- convertincometointeger(train1)
set.seed(100)

spl <- sample.split(train6$Choice, SplitRatio = 0.7)
trainoftrain6 <- subset(train6, spl == TRUE)
trainoftest6 <- subset(train6, spl == FALSE)
trainoftrainnew6 <- subset(trainoftrain6, select = - c(92,93,94,95))
trainoftestnew6 <- subset(trainoftest6, select = - c(92,93,94,95))

#Train 7 1.228603
train7 <- train
train7 <- factorise(train7)
train7$Choice <- factor(train7$Choice)
train7$income <- factor(train7$income)
set.seed(100)

spl <- sample.split(train7$Choice, SplitRatio = 0.7)
trainoftrain7 <- subset(train7, spl == TRUE)
trainoftest7 <- subset(train7, spl == FALSE)
trainoftrainnew7 <- subset(trainoftrain7, select = - c(1,2,3,95,96,97,98))
trainoftestnew7 <- subset(trainoftest7, select = - c(1,2,3,95,96,97,98))

##Train 8 1.228622
train8 <- train
train8 <- factorise(train8)
train8 <- convertincometointeger(convertincome_train(train8)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
train8$Choice <- factor(train8$Choice)
train8$income <- factor(train8$income)
train8$Price1 <- factor(train8$Price1)
train8$Price2 <- factor(train8$Price2)
train8$Price3 <- factor(train8$Price3)
train8$Price4 <- factor(train8$Price4)
set.seed(100)

spl <- sample.split(train8$Choice, SplitRatio = 0.7)
trainoftrain8 <- subset(train8, spl == TRUE)
trainoftest8 <- subset(train8, spl == FALSE)
trainoftrainnew8 <- subset(trainoftrain8, select = - c(1,2,3,64:83,95,96,97,98))
trainoftestnew8 <- subset(trainoftest8, select = - c(1,2,3,64:83,95,96,97,98))

## Train all, test
train_all <- train
train_all <- factorise(train_all)
train_all <- convertincometointeger(convertincome_train(train_all)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
train_all$Choice <- factor(train_all$Choice)
train_all$income <- factor(train_all$income)
train_all$Price1 <- factor(train_all$Price1)
train_all$Price2 <- factor(train_all$Price2)
train_all$Price3 <- factor(train_all$Price3)
train_all$Price4 <- factor(train_all$Price4)

train_allnew <- subset(train_all, select = - c(1,2,3,95,96,97,98))

test <- read.csv("test.csv", stringsAsFactors = FALSE)
test_all <- test
test_all[is.na(test_all)] <- 0 # adds 0 to all missing values
test_all <- factorise(test_all)
test_all <- convertincometointeger(convertincome_train(test_all)) # converts '$290,000 to $299,999' to '$300,000 and over', then take the middle value.
test_all$income <- factor(test_all$income)
test_all$Price1 <- factor(test_all$Price1)
test_all$Price2 <- factor(test_all$Price2)
test_all$Price3 <- factor(test_all$Price3)
test_all$Price4 <- factor(test_all$Price4)

test_allnew <- subset(test_all, select = - c(1,2,3,95,96,97,98))


## Model C4.5
information.gain(Choice ~ ., data = trainoftrainnew4)
modelC45 <- J48(as.factor(Choice) ~ ., data = trainoftrainnew5, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = trainoftestnew5, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
logloss<- -(sum(log(predC45)*trainoftest5[,95:98]))/N
logloss #1.439258


modelC45 <- J48(Choice ~ ., data = train_all, control = Weka_control(A = TRUE, R = FALSE))
predC45 <- predict(modelC45, newdata = test1sub, type = "probability")
head(predC45, 1)
N <- nrow(predC45)
sum(predC45[1,])
#write.csv(predC45, "submissionDay3_2.csv")

##Bagging
modelBag1 <- Bagging(Choice ~ ., data = trainoftrainnew, control = Weka_control(P = 70, W = "weka.classifiers.trees.J48"))
predBag <- predict(modelBag1, newdata = trainoftestnew, type = "probability")
head(predBag,5)
sum(predBag[1,])
N <- nrow(predBag)
logloss<- -(sum(log(predBag)*trainoftest[,95:98]))/N
logloss #NaN

## CostSensitiveClassifier
csc1 <- CostSensitiveClassifier(Choice ~ ., data = train_all)
summary(csc1)
```

```{r}
trainwide2 <- mlogit.data(train, shape = "wide", choice = "Choice", varying = c(4:83,95:98), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
predictors <- as.data.frame(subset(trainwide, select = -c(1,2,3,15:20,41)))
depvar <- as.data.frame(trainwide[,15:18])
nb2 <- naiveBayes(y=depvar,x = predictors, data = trainwide)
```


###Naive Bayes
```{r}
library(e1071)
nb1 <- naiveBayes(Choice ~ ., data = trainoftrainnew8)
#summary(nb1)
prednb1 <- predict(nb1, newdata = trainoftestnew8, type = "raw")
head(prednb1, 1)
N <- nrow(prednb1)
sum(prednb1[1,])
logloss<- -(sum(log(prednb1)*trainoftest8[,95:98]))/N
logloss
#write.csv(prednb1, "naivebayes3.csv")

train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainnb <- train
trainnb <- convertincome_train(trainnb)

trainnb_train <- subset(trainnb, Task<=5)
trainnb_test <- subset(trainnb, Task>5)

set.seed(100)
library(caTools)
spl <- sample.split(trainnb, SplitRatio = 0.5)
trainnb_trainrand <- subset(trainnb, spl==TRUE)
trainnb_testrand <- subset(trainnb, spl==FALSE)

trainnb_trainsub <- subset(trainnb_train, select = - c(1,2,3,95:98)) # remove ch1,ch2,ch3,ch4 columns
trainnb_testsub <- subset(trainnb_test, select = - c(1,2,3,95:98))

x <- as.data.frame(lapply(trainnb_trainsub[,1:90],factor))
y <- trainnb_trainsub[,92]
#GN+NS+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+HU+AF+BU+Price | income + segment + educ + age + region + Urb + ppark + gender
nb2 <- naiveBayes(Choice ~ 
                    GN1+NS1+FA1+LD1+BZ1+FC1+FP1+RP1+PP1+SC1+TS1+NV1+MA1+LB1+HU1+AF1+BU1+Price1+
                    GN2+NS2+FA2+LD2+BZ2+FC2+FP2+RP2+PP2+SC2+TS2+NV2+MA2+LB2+HU2+AF2+BU2+Price2+
                    GN3+NS3+FA3+LD3+BZ3+FC3+FP3+RP3+PP3+SC3+TS3+NV3+MA3+LB3+HU3+AF3+BU3+Price3+
                    income + segment + miles + age + region + Urb + ppark
                  , data = as.data.frame(lapply(trainnb_trainrand, factor)))
prednb2 <- predict(nb2, newdata = as.data.frame(lapply(trainnb_testrand, factor)), type = "raw")
-(sum(log(prednb2)*trainnb_testrand[,95:98]))/nrow(prednb2)

#8:                     FA1+BZ1+FC1+FP1+HU1+Price1+AF1+BU1+

trainnb_mlogit <- mlogit.data(as.data.frame(lapply(trainnb, factor)), shape = "wide", choice = "Choice", varying = c(4:83), sep = "", alt.levels = c("Ch1","Ch2","Ch3","Ch4"), id.var = "Case")
trainnb_mlogitsub <- subset(trainnb_mlogit, select = -c(1,2,3,15:18,20,41))

#subs1 <- regsubsets(as.factor(Choice)~., trainnb_mlogitsub, nvmax = 31, really.big = TRUE, method = "exhaustive")

#Choice ~ 
#                    CC1+GN1+NS1+FA1+LD1+BZ1+FC1+FP1+RP1+PP1+KA1+SC1+TS1+NV1+MA1+LB1+HU1+AF1+BU1+Price1+
#                    CC2+GN2+NS2+FA2+LD2+BZ2+FC2+FP2+RP2+PP2+KA2+SC2+TS2+NV2+MA2+LB2+HU2+AF2+BU2+Price2+
#                    CC3+GN3+NS3+FA3+LD3+BZ3+FC3+FP3+RP3+PP3+KA3+SC3+TS3+NV3+MA3+LB3+HU3+AF3+BU3+Price3+
#                    income + segment + miles + age + region + Urb + ppark + year
nbY <- naiveBayes(Choice ~ 
                    GN1+NS1+FA1+LD1+BZ1+FC1+FP1+RP1+PP1+SC1+TS1+NV1+MA1+LB1+HU1+AF1+BU1+Price1+
                    GN2+NS2+FA2+LD2+BZ2+FC2+FP2+RP2+PP2+SC2+TS2+NV2+MA2+LB2+HU2+AF2+BU2+Price2+
                    GN3+NS3+FA3+LD3+BZ3+FC3+FP3+RP3+PP3+SC3+TS3+NV3+MA3+LB3+HU3+AF3+BU3+Price3+
                    segment + miles + age + region + Urb + ppark
                  , data = trainnb)
predbnY <- predict(nbY, newdata = test, type = "raw")
write.csv(predbnY, "bestbn.csv")
```

###SVM
```{r}
library(e1071)
svm1 <- svm(Choice ~., data = trainoftrainnew7) #Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : contrasts can be applied only to factors with 2 or more levels
# got zeros in section 4
predsvm1 <- predict(svm1, newdata = trainoftestnew7)
```

